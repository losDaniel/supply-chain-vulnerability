{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4357a32e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Baseline Supply Chain Scraper\n",
    "\n",
    "This notebook runs the scraper for our baseline sample. This consists of IDs that we have collected from different sources. Below, we describe the sample we used to begin with. This gave us a first body of IDs. The next phase is randomization (below) which simply tries to guess and record IDs. \n",
    "\n",
    "#### <font color=amber>Supermarket in Tokyo Sample<font>\n",
    "\n",
    "    Satoshi’s friend took photos of beef sold in a supermarket in Tokyo Sep.13 2021\n",
    "\n",
    "#### <font color=amber>Recalled Sample<font>\n",
    "    \n",
    "    Due to the possibility of nonstandard ID tags, one maker recalls the suspicious ID tags distributed in FY2020. The company announced the ID numbers subject to the recall on its website. Satoshi is confused! Especially for smaller ID numbers on the list, Satoshi found the IDs are already registered in the database. If the IDs are newly issued in 2020, why are they already on the database? One possibility is the tags accidentally came off and the farmers needed to get new tags with the same IDs. Another possibility is that the gov reuses the same IDs several years after death, or slaughter. Considering the average life years of cattle/cow (= 5~6 yrs), the latter is more plausible.\n",
    "    \n",
    "#### <font color=amber>Fukushima Tracking Sample<font>\n",
    "    \n",
    "    For accountability to citizens, the gov published the IDs of cattle and their descendants raised within 20 km from the Fukushima nuclear power plant as of March 31 in 2012. The cattle should not be shipped to slaughterhouses because they are considered “contaminated by radiation”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6916c5d2",
   "metadata": {},
   "source": [
    "**Import the module:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b51b3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supply_chain_mapping import supply_chain_data_scraper as scd\n",
    "from supply_chain_mapping import random_id_generator as rig "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9acf3",
   "metadata": {},
   "source": [
    "**Original Sample:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc0afa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of ids in Tokyo SM sample: 7\n",
      "# of ids in Fukushima sample: 340\n",
      "# of ids in Recall sample: 7000\n",
      "Total # of ids in our baseline sample: 7347\n"
     ]
    }
   ],
   "source": [
    "# Import the three samples \n",
    "sample_recall, sample_fukushima, sample_tokyo_sm = scd.quickload_samples()\n",
    "\n",
    "print('# of ids in Tokyo SM sample:', len(sample_tokyo_sm))\n",
    "print('# of ids in Fukushima sample:', len(sample_fukushima))\n",
    "print('# of ids in Recall sample:', len(sample_recall))\n",
    "\n",
    "master_sample = sample_tokyo_sm.append(sample_fukushima)\n",
    "master_sample = master_sample.append(sample_recall)\n",
    "\n",
    "print('Total # of ids in our baseline sample:', len(master_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d186d1",
   "metadata": {},
   "source": [
    "*Review how much of the initial sample has been collected:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28bedff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 IDs in the submitted list have not been collected\n",
      "760 new IDs in the temporary folder have been appended to 98261 IDs in the collected folder\n",
      "There are a total of 99021  collected IDs\n",
      "There are a total of 139154 failed IDs\n"
     ]
    }
   ],
   "source": [
    "uncollected_sample = scd.check_collected_data(list(master_sample['id'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea4b390",
   "metadata": {},
   "source": [
    "**Generate completely random and unique IDs that do not overlap with collected ones (including failed ones):**\n",
    "\n",
    "We go through this step first in order to identify rules in how IDs are generated which we can then use to create targetted random IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e61cddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncollected_random_ids = rig.random_cowid_generator(batch_size=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0917b7d2",
   "metadata": {},
   "source": [
    "**Examine Generate random IDs based on collected ones:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c405732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01        1\n",
      "02      282\n",
      "03       10\n",
      "04       16\n",
      "05        7\n",
      "06        6\n",
      "07       44\n",
      "08     6827\n",
      "10       17\n",
      "11    20842\n",
      "12    27155\n",
      "13    31174\n",
      "14     5534\n",
      "15     4644\n",
      "16     2462\n",
      "Name: dig2, dtype: int64\n",
      "11    33867\n",
      "12    27448\n",
      "13    23729\n",
      "14    10831\n",
      "15    11735\n",
      "16    13902\n",
      "17    15379\n",
      "18     1157\n",
      "19     1106\n",
      "Name: dig2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any patterns in the digits of the IDs that do not fail \n",
    "import pandas as pd\n",
    "collected_ids, failed_ids = scd.get_collected_ids()\n",
    "collected_ids = pd.DataFrame({'collected':collected_ids})\n",
    "for i in range(2,4): collected_ids['dig'+str(i)] = collected_ids['collected'].str[:i]\n",
    "print(collected_ids['dig2'].value_counts().sort_index())\n",
    "\n",
    "failed_ids = pd.DataFrame({'failed':failed_ids})\n",
    "for i in range(2,4): failed_ids['dig'+str(i)] = failed_ids['failed'].str[:i]\n",
    "print(failed_ids['dig2'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "846aed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_random_ids = rig.bounded_random_ids(['08','11','12','13','14','15','16'], 2, batch_size=100000, lower_bound=11000000, upper_bound=14000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a849e",
   "metadata": {},
   "source": [
    "### <font color=maroon>Scraping the original supply chain sample!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19230f1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of uncollected IDs from the original sample is 100000\n",
      "The project path is:\n",
      " G:\\My Drive\\Supply Chain Vulnerability\\supply-chain-vulnerability\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from path import Path\n",
    "project_path = Path(os.getcwd()).parent\n",
    "\n",
    "print('The number of uncollected IDs from the original sample is',len(list_of_random_ids))\n",
    "print('The project path is:\\n',project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data, complete_data, failures  = scd.supply_chain_data_scraper(list_of_random_ids, \n",
    "                                                                    japanese=True, \n",
    "                                                                    split_save=200,\n",
    "                                                                    temporary_file_path=project_path+'/data/temporary',\n",
    "                                                                    final_file_path=project_path+'/data/collected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724b795",
   "metadata": {},
   "source": [
    "# Scraper Evaluation \n",
    "\n",
    "To evaluate a reasonable stopping point we can use the marginal entropy of each additional unit scraped. In other words, how much new information about our network do we get with each additional cow. \n",
    "\n",
    "The following functions describe the number of nodes and number of connections for each additional ID scraped. It randomly samples IDs until the entire sample is acccounted for and then repeats this process in a monte-carlo simulation. The resulting rates of change and confidence intervals are graphed.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24171fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supply_chain_mapping import data_cleaning_and_processing as dc\n",
    "from supply_chain_mapping import visualizations as vz\n",
    "\n",
    "complete_data = dc._load_complete_data(rename=True) # Rename vairbles from japanese to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac63bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample: 3\n",
      "Accounting for: 348819  samples\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vz.plot_scraper_entropy(15000, complete_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a992e4b",
   "metadata": {},
   "source": [
    "*The graph shows that the number of new edges and nodes gained for each new ID flattens after 90,000 IDs. Considering that 135,000 failed IDs were collected to collect the valid 96,000 marginal rate of entropy is less than half that on the graph. Thus, we consider this a good stopping point.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
