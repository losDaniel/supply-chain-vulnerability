import os
from path import Path 
root = str(Path(os.path.abspath(os.path.dirname(__file__))).parent)

import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

import supply_chain_mapping.data_cleaning_and_processing as dc
from supply_chain_mapping import network_analysis as na

import re 
import pandas as pd
import  numpy  as  np
from  japanmap  import  picture
from vcue.basics import remove_values_from_list
from vcue.data import order

import networkx as nx

import  matplotlib.pyplot  as  plt 
from  pylab  import  rcParams


def plot_scraper_entropy(factor, complete_data):
    
    num_edges, num_nodes, num_ids = dc._get_scraper_entropy_data(factor, complete_data)
    # Create traces
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=num_ids, y=num_edges,
                        mode='lines',
                        name='# edges'))
    fig.add_trace(go.Scatter(x=num_ids, y=num_nodes,
                        mode='lines',
                        name='# nodes'))
    
    fig.update_layout(title='Number of Edges & Nodes by IDs Scraped')
    
    fig.show()


def _plot_on_map(summary, slaughter_summary):
    '''Plot data on the map'''
    japan_summary = summary[["PrefJ","node","Prefecture"]].merge(slaughter_summary, on='Prefecture', how='inner')
    
    
    japan_summary['Cow_P'] = japan_summary['#Cows']/japan_summary['#Cows'].sum()
    
    perf_list = japan_summary['PrefJ'].values
    rate = japan_summary['Cow_P'].values
    rf = rate.astype(np.float32)

    def color_scale(r): 
        return(0, int(255 - 255/np.max(rf) * r), 255)
    
    data = {} 
    for p, r in zip(perf_list, rf): 
        c  =  color_scale(r) 
        data[p] = c
    
    rcParams['figure.figsize'] = 14, 14 
    plt.imshow(picture (data));

def plot_ids_by_prefecture(summary, title='Scraped IDs by Prefecture',y='node',x='Prefecture',text='#Cows'):
    '''Plots a bar graph showing the number of cows that started their grim journey in each prefecture'''
    fig = px.bar(summary, y=y, x=x, text=text)
    fig.update_traces(texttemplate='%{text:.2s}', textposition='outside', marker_color='orange')
    fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide', title=title)
    fig.show()
    
    
def plot_nodes_ids_by_prefecture(summary, title='# of Nodes & Cows by Prefecture'):    
    '''Plots a double bar graph with number of '''
    x = summary['Prefecture'].values
    y1 = summary['node'].values
    y2 = summary['#Cows'].values
    
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=x,
        y=y1,
        name='Nodes',
        marker_color='indianred',
    ))
    fig.add_trace(go.Bar(
        x=x,
        y=y2,
        name='#Cows',
        marker_color='lightsalmon',
    ))
    
    # Here we modify the tickangle of the xaxis, resulting in rotated labels.
    fig.update_layout(barmode='group', xaxis_tickangle=-45, title=title)
    #fig.write_image(project_path+'/documents/# of Nodes & Cows by Prefecture', format='pdf', engine='kaleido')
    #fig.write_html(project_path+'/documents/# of Nodes & Cows by Prefecture.html')
    fig.show()




def elbow_plot_inertia(wss, clusters, highlight):
    # Using elbow method to select the correct number of clusters    
    _ = plt.figure(figsize = (10,7))
    _ = plt.plot(clusters, wss, linewidth = 2, color = 'blue', marker='+', markersize = 8)
    _ = plt.title('Elbow Method', fontsize = 12)
    _ = plt.xlabel('Number of Clusters',fontsize = 10)
    _ = plt.ylabel('Inertia',fontsize = 10)
    
    n_clusters = highlight
    
    _ = plt.axvline(x = n_clusters, linewidth = 2, color = 'red', linestyle = '--')
    _ = plt.show()



def graph_node_consistency_by_year(df, years, years_to_use=1, use_list_interval=True):
    
    vanishing_nodes, persistent_nodes, incoming_nodes = [], [], []  
    for i, year in enumerate(years): 
        
        if use_list_interval:
            j = i + 1 
            try: 
                # Try to get the next year on the list
                next_year = int(years[j])
            except: 
                # If it is not available simple set the max date as one year after the last one
                next_year = int(years[i])+years_to_use
        else: 
            next_year = int(years[i])+years_to_use

        try: 
            vanishing_nodes.append(df.loc[(year,'A not B'), next_year])
            persistent_nodes.append(df.loc[(year,'A and B'), next_year])
            incoming_nodes.append(df.loc[(year,'B not A'), next_year])
        except: 
            pass

    visuals = pd.DataFrame({'In Network: Vanishing Nodes':vanishing_nodes,'In Network: Persistent Nodes':persistent_nodes,'Incoming Nodes':incoming_nodes}, index=years[:-1]) 
    visuals = pd.DataFrame(visuals.stack()).reset_index()
    visuals.columns = ['Year','Detection','Value']


    fig = px.area(visuals, x="Year", y="Value", color="Detection",
                  line_group="Detection")
    fig.update_layout(
        title=go.layout.Title(
            text="Network Consistency Year over Year<br><sup>Incoming and persistent nodes are the nodes IN a network any given year.<br>Incoming nodes replace vanishing nodes in our sample each year.</sup>",
            xref="paper",
            x=0
        ),
    )
    fig.show()


    
def plot_degrees_out_in_directedG(g):

    out_d=list(dict(g.out_degree()).values())
    in_d=list(dict(g.in_degree()).values())
    
    ######NEED to eliminate ZEROS
    in_d=remove_values_from_list(in_d,0)
    out_d=remove_values_from_list(out_d,0)
    
    out_weighted=list(dict(g.out_degree(weight='weight')).values())
    in_weighted=list(dict(g.in_degree(weight='weight')).values())
    ######NEED to elkminate ZEROS
    out_weighted=remove_values_from_list(out_weighted,0)
    in_weighted=remove_values_from_list(in_weighted,0)
    
    fig, ax = plt.subplots()
    fig.set_size_inches((9, 7))
    
    n_bins = 20
    
    #n, bins = np.histogram(out_d, bins = range(min(out_d), max(out_d)+1, 2), normed="True") 
    out_logBins = np.logspace(np.log10(min(out_d)), np.log10(max(out_d)),num=n_bins)
    out_logBinDensity, out_binedges = np.histogram(out_d, bins=out_logBins, density=True)
    
    #n, bins = np.histogram(in_d, bins = range(min(in_d), max(in_d)+1, 2), normed="True") 
    in_logBins = np.logspace(np.log10(min(in_d)), np.log10(max(in_d)),num=n_bins)
    in_logBinDensity, in_binedges = np.histogram(in_d, bins=in_logBins, density=True)
    
    ax.loglog(out_logBins[:-1],out_logBinDensity,'o', markersize=10,label=r'$k_{in}$')
    ax.loglog(in_logBins[:-1],in_logBinDensity,'s', markersize=10,label=r'$k_{out}$')
    ax.legend(fontsize=30)
    
    
    ax.set_xlabel('$degree, k$',fontsize=40)
    ax.set_ylabel('$P(k)$',fontsize=40) 
    plt.savefig("distributions.eps",dpi=200,bbox_inches='tight')
    
    


def _vector_result_data(results_data, var):
    
    em_data = results_data.loc['empirical network'][[var]].values
    em_data = em_data.reshape(len(em_data),)

    sw_index = [idx for idx in results_data.index if 'small world' in idx]
    sw_data = results_data.loc[sw_index][[var]].values
    sw_data = sw_data.reshape(len(sw_data),)
    
    ba_index = [idx for idx in results_data.index if 'Barabasi-Albert' in idx]
    ba_data = results_data.loc[ba_index][[var]].values
    ba_data = ba_data.reshape(len(ba_data),)
    
    er_index = [idx for idx in results_data.index if 'Erdős-Rényi' in idx]
    er_data = results_data.loc[er_index][[var]].values
    er_data = er_data.reshape(len(er_data),)
    
    return em_data, sw_data, ba_data, er_data

def plot_model_fit_over_time(results_data):
    cols_to_graph = ['# of link','<C>','<K>','<L>']
    
    fig = make_subplots(rows=2, cols=2)
    
    years = list(results_data['year'].unique())#.astype(str).unique())
    
    on_col = True 
    row = 1 
    col = 1 
    for var in cols_to_graph:
        
        em_data, sw_data, ba_data, er_data = _vector_result_data(results_data, var)
    
        # Create traces
        fig.add_trace(go.Scatter(x=years, y=em_data,
                            mode='lines',
                            name='empirical_'+var,
                            line = dict(color='royalblue', width=4, dash='solid')),
                     row=row, col=col)
    
        fig.add_trace(go.Scatter(x=years, y=sw_data,
                            mode='lines',
                            name='small world_'+var,
                            line = dict(color='lightgreen', width=4, dash='solid')),
                     row=row, col=col)
    
        fig.add_trace(go.Scatter(x=years, y=ba_data,
                            mode='lines',
                            name='barabasi-albert_'+var,
                            line = dict(color='darksalmon', width=4, dash='solid')),
                     row=row, col=col)
    
        fig.add_trace(go.Scatter(x=years, y=er_data,
                            mode='lines', name='erdos renyi_'+var,
                            line = dict(color='maroon', width=4, dash='solid')),
                     row=row, col=col)
        if on_col: 
            col+=1
            on_col=False
        else: 
            row+=1
            col=1
            on_col=True
    
    fig.update_layout(height=800, width=1600, title_text="Network Attributes Over Time")
    
    return fig

def loglogplot_model_degree_distribution(empirical_graphs, ws_graphs, ba_graphs, er_graphs, year, save_as="./networkplot.png"):

    #G1:empirical
    degs0 = list(dict(nx.degree(empirical_graphs[year])).values())
    n0, bins0 = np.histogram(degs0, bins = list(range(min(degs0), max(degs0)+1, 1)), density="True")
    
    #Gs:Small World
    degs1 = list(dict(nx.degree(ws_graphs[year])).values())
    n1, bins1 = np.histogram(degs1, bins = list(range(min(degs1), max(degs1)+1, 1)), density="True")
    
    #Gb:Barabasi Albert
    degs2 = list(dict(nx.degree(ba_graphs[year])).values())
    n2, bins2 = np.histogram(degs2, bins = list(range(min(degs2), max(degs2)+1, 1)), density="True")
    
    #Ge:Erdos Renyi
    degs3 = list(dict(nx.degree(er_graphs[year])).values())
    n3, bins3 = np.histogram(degs3, bins = list(range(min(degs3), max(degs3)+1, 1)), density="True")
    
    plt.figure(figsize=(17,8)) #use once and set figure size
    plt.loglog(bins0[:-1],n0,'b-', markersize=10, label="Empirical Data") 
    plt.loglog(bins1[:-1],n1,'bs--', markersize=10, label="Small World") 
    plt.loglog(bins2[:-1],n2,'go--', markersize=10, label="Barabasi Albert") 
    plt.loglog(bins3[:-1],n3,'r*--', markersize=10, label="Erdos Renyi")
    plt.legend(loc='upper right',prop={'size': 30})
    plt.title('Degree Distributions log-log plot',fontsize=30,y=1.1)
    plt.xlabel('Degree, k',fontsize=30)
    plt.ylabel('P(k)',fontsize=30)
    plt.xticks(fontsize=30)
    plt.yticks(fontsize=30)
    plt.tight_layout()
    plt.savefig(save_as)
    plt.show;


def graph_community_attributes_over_time(graphs_by_slaughter_year, years, louvain = True,  k_clique_3 = True, louvain_data=None, k_clique_data=None): #k_clique_2 = False,

        
    if (louvain) and (louvain_data is None): 
        louvain_data, louvain_c = na.communities_over_time(graphs_by_slaughter_year, years, louvain=True, k_clique=False)
    # if k_clique_2:
    #     k_clique_data_2, k_clique_c_2 = na.communities_over_time(graphs_by_slaughter_year, years, louvain=False, k_clique=True, k_clique_min_connections=2)
    if (k_clique_3) and (k_clique_data is None):
        k_clique_data_3, k_clique_c_3 = na.communities_over_time(graphs_by_slaughter_year, years, louvain=False, k_clique=True, k_clique_min_connections=3)
        
    x_axis = list(louvain_data.index)
        
    on_col = True 
    row = 1 
    col = 1 
    
    cols_to_graph = ['Total # Comm','% Nodes in Comms','max','50%','mean','std']
    
    fig = make_subplots(rows=3, cols=2, subplot_titles=tuple(cols_to_graph))
    
    for var in cols_to_graph:
        
        
        if louvain:
            louvain_vals = list(louvain_data[var].values)
    
            # Create traces
            fig.add_trace(go.Scatter(x=x_axis, y=louvain_vals,
                                mode='lines',
                                name='Louvain: '+var,
                                line = dict(color='maroon', width=4, dash='solid')),
                         row=row, col=col)
    
        # if k_clique_2:
        #     k_clique_vals_2 = list(k_clique_data_2[var].values)
    
        #     fig.add_trace(go.Scatter(x=x_axis, y=k_clique_vals_2,
        #                         mode='lines',
        #                         name='K(2)-Clique :'+var),
        #                  row=row, col=col)
    
        if k_clique_3:
            k_clique_vals_3 = list(k_clique_data_3[var].values)
    
            fig.add_trace(go.Scatter(x=x_axis, y=k_clique_vals_3,
                                mode='lines',
                                name='K(3)-Clique :'+var,
                                line = dict(color='royalblue', width=4, dash='solid')),
                         row=row, col=col)
    
            
            
        if on_col: 
            col+=1
            on_col=False
        else: 
            row+=1
            col=1
            on_col=True
        
    fig.update_layout(height=800, width=1600, title_text="Community Attributes Over Time")    
    
    return fig, louvain_data, k_clique_data_3, louvain_c, k_clique_c_3


def plot_network_ages(s_network_age):
    s_network_age = order(s_network_age, 'sample_year').sort_values('sample_year',ascending=False)
    s_network_age
    
    s_net_plot = s_network_age.drop('sample_year',1)
    s_net_plot['max_col'] = s_net_plot.sum(axis=1)
    for c in s_net_plot.columns:
        s_net_plot[c] = s_net_plot[c]/s_net_plot['max_col']
    s_net_plot = s_net_plot.drop('max_col',1)
    
    plot_years = sorted([int(i) for i in s_net_plot.columns])
    s_net_plot = order(s_net_plot, plot_years)
    
    
    fig = go.FigureWidget()
        
    fig.add_trace(go.Heatmap(
        z=s_net_plot.fillna(0),
        x=plot_years,
        y=s_network_age['sample_year'].values,
        text = s_network_age.drop('sample_year',1),
        colorscale='Agsunset',
        zmin=0,
        zmax=0.5
    ))
    
    fig.update_layout(
        title="Age of Network Data by Sample Year",
        xaxis_title="network built using movements sampled from this year",
        yaxis_title="sample year",
        legend_title="Legend Title",
        font=dict(
            family="Courier New, monospace",
            size=12,
            color="RebeccaPurple"
        )
    )

    return fig 

#~
def import_plotly_color_scales(shuffle=True):
    
    from_white_scales = ['Blues','BuGn','BuPu','GnBu','Greens','Greys','PuBu','PuBuGn','Purples','RdPu','amp','tempo']

    return from_white_scales

def import_plotly_color_list(shuffle=True):
    
    color_list = """aliceblue, antiquewhite, aqua, aquamarine, azure,
            beige, bisque, black, blanchedalmond, blue,
            blueviolet, brown, burlywood, cadetblue,
            chartreuse, chocolate, coral, cornflowerblue,
            cornsilk, crimson, cyan, darkblue, darkcyan,
            darkgoldenrod, darkgray, darkgrey, darkgreen,
            darkkhaki, darkmagenta, darkolivegreen, darkorange,
            darkorchid, darkred, darksalmon, darkseagreen,
            darkslateblue, darkslategray, darkslategrey,
            darkturquoise, darkviolet, deeppink, deepskyblue,
            dimgray, dimgrey, dodgerblue, firebrick,
            floralwhite, forestgreen, fuchsia, gainsboro,
            ghostwhite, gold, goldenrod, gray, grey, green,
            greenyellow, honeydew, hotpink, indianred, indigo,
            ivory, khaki, lavender, lavenderblush, lawngreen,
            lemonchiffon, lightblue, lightcoral, lightcyan,
            lightgoldenrodyellow, lightgray, lightgrey,
            lightgreen, lightpink, lightsalmon, lightseagreen,
            lightskyblue, lightslategray, lightslategrey,
            lightsteelblue, lightyellow, lime, limegreen,
            linen, magenta, maroon, mediumaquamarine,
            mediumblue, mediumorchid, mediumpurple,
            mediumseagreen, mediumslateblue, mediumspringgreen,
            mediumturquoise, mediumvioletred, midnightblue,
            mintcream, mistyrose, moccasin, navajowhite, navy,
            oldlace, olive, olivedrab, orange, orangered,
            orchid, palegoldenrod, palegreen, paleturquoise,
            palevioletred, papayawhip, peachpuff, peru, pink,
            plum, powderblue, purple, red, rosybrown,
            royalblue, rebeccapurple, saddlebrown, salmon,
            sandybrown, seagreen, seashell, sienna, silver,
            skyblue, slateblue, slategray, slategrey, snow,
            springgreen, steelblue, tan, teal, thistle, tomato,
            turquoise, violet, wheat, white, whitesmoke,
            yellow, yellowgreen"""
            
    parsed_colors = re.findall('([a-z]*)', color_list)
    parsed_colors = [c for c in parsed_colors if c!='']
    
    if shuffle: 
        import random
        random.shuffle(parsed_colors)
        parsed_colors
    
    return parsed_colors