import os
from path import Path 
root = str(Path(os.path.abspath(os.path.dirname(__file__))).parent)

import supply_chain_mapping.data_cleaning_and_processing as dc

import pandas as pd
import numpy as np
import networkx as nx
import random


random.seed(1)


def sample_network(graph_data, 
                   sample_by_percentage=None, 
                   sample_by_year=False, 
                   sample_by_slaughter=False, 
                   sample_by_origin=False, 
                   min_date=None,
                   max_date=None):
    '''Take a sample of the network movement to identify nodes and edges to build the network with. 
    __________
    parameters
    - sample_by_percentage : 0 < flaot < 1. Takes a random sample of this % size from the total IDs in the dataset of movements. This can be applied in combinationwith one other sampling method to take a random sample of IDs in that sample.  
    - sample_by_year : bool, default False. If True, only uses movements after min_date and before max_date  
    - sample_by_slaughter : bool, default False. If True, collected the IDs of cows slaughtered after min_date and before max_date and use all of their movements to map the network 
    - sample_by_origin : bool, default False. If True, collected the IDs of cows whose journey began after min_date and before max_date and use all of their movements to map the network 
    - min_date : str in format '01/01/2020', default None. 
    - max_date : str in format '01/01/2020', default None.     
    '''

    if sample_by_year or sample_by_slaughter or sample_by_origin:
        assert min_date is not None 
        assert max_date is not None 
    else: 
        try: assert sample_by_percentage 
        except Exception as e: 
            print('Must select at least one sampling method')
            raise e 
        movements = graph_data # If we're not sampling using dates 

    if sample_by_year:     
        try:
            assert sample_by_slaughter is False 
            assert sample_by_origin is False
        except Exception as e: 
            print('More than one date-based sampling method cannot be used simultaneously')
            raise e 
        # Sample the movements based on whether they were moved within a given year        
        # We use the destination date to track movement because all destinations indicate movement within the network (eventually to slaughter)
        # whereas the date of origin includes birth which is a non-movement across the network 
        movements = graph_data[((graph_data['date_destination']>min_date) & (graph_data['date_destination']<max_date))]
        
    if sample_by_slaughter:
        try:
            assert sample_by_year is False 
            assert sample_by_origin is False 
        except Exception as e: 
            print('More than one date-based sampling method cannot be used simultaneously')
            raise e 
        # keep the dates of slaughters and check the dates of slaughter fall within range 
        movements = graph_data[graph_data['status_destination']=='Slaughter']
        movements = movements[(movements['date_destination']>min_date) & (movements['date_destination']<max_date)]
        # If sampling by slaughter or origin we are using IDs and not movements for sampling 
        ids_to_use = list(movements['Individual Identification  Number'].unique()) 
        movements = graph_data[graph_data['Individual Identification  Number'].isin(ids_to_use)] # Keep all the movements of the cows with the selected IDs 
    
    if sample_by_origin:
        try:
            assert sample_by_year is False 
            assert sample_by_slaughter is False 
        except Exception as e: 
            print('More than one date-based sampling method cannot be used simultaneously')
            raise e
        # Sort by cow and date and keep the first obs for each cow.         
        movements = graph_data.sort_values(['Individual Identification  Number','date_origin']).groupby('Individual Identification  Number', as_index=False).first()
        movements = movements[(movements['date_destination']>min_date) & (movements['date_destination']<max_date)]
        # If sampling by slaughter or origin we are using IDs and not movements for sampling 
        ids_to_use = list(movements['Individual Identification  Number'].unique()) 
        movements = graph_data[graph_data['Individual Identification  Number'].isin(ids_to_use)] # Keep all the movements of the cows with the selected IDs 
    
    if sample_by_percentage is not None:
        # Take a sample of the data. Default is the full dataset  # clocked 1.46s 
        num_unique_ids = len(list(movements['Individual Identification  Number'].unique()))
        ids_to_use = random.sample(list(movements['Individual Identification  Number'].unique()), int(np.floor(num_unique_ids*sample_by_percentage)))
        movements = movements[movements['Individual Identification  Number'].isin(ids_to_use)]
        
    return movements 
    

def get_networks(graph_data, directed=True):
    
    # Create a dataset of origin attributes for each node 
    summ_cols = ['date_origin','duration'] + list(graph_data['status_origin'].unique())
    node_origin_attributes = pd.concat([graph_data, pd.get_dummies(graph_data['status_origin'])], 1)[['origin']+summ_cols].groupby('origin').mean()
    
    # Create a dataset of origin attributes for each node 
    summ_cols = ['date_destination'] + list(graph_data['status_destination'].unique())
    node_destination_attributes = pd.concat([graph_data, pd.get_dummies(graph_data['status_destination'])], 1)[['destination']+summ_cols].groupby('destination').mean()
    
    # Merge the origin and destination atrributes for each node 
    node_info = node_origin_attributes.merge(node_destination_attributes, right_index=True, left_index=True, indicator=True, suffixes=('_org','_dst'))
    
    if sample_p<1:
        # Take a sample of the data. Default is the full dataset  # clocked 1.46s 
        ids_to_use = random.sample(list(graph_data['Individual Identification  Number'].values), int(np.floor(len(graph_data)*sample_p)))
        graph_data_sample = graph_data[graph_data['Individual Identification  Number'].isin(ids_to_use)]
    else: 
        graph_data_sample = graph_data
    
    # Collapse the network based on origin-destination connections to get the edges of the networks 
    graph_data_sample['weight'] = 1 
    edges = graph_data_sample.groupby(['origin','destination'],as_index=False)['weight'].sum()
    edges['weight'] = edges['weight']/edges['weight'].max()
    print('Weight distribution parameters:') 
    print(edges['weight'].describe())
    
    
    if directed: 
        Gn = nx.DiGraph() 
    else: 
        Gn = nx.Graph() 
    
    # Transpose the node-info 
    node_info_T = node_info.transpose()
    
    attr=node_info_T.index.values    
    
    for col in node_info_T.columns:
        attr_node=dict(list(zip(attr, node_info_T[col].values)))
        Gn.add_node(col,attr_dic=attr_node)
    
    # Read in the edges for the network 
    for tup in edges.itertuples():
        Gn.add_edge(tup.origin, tup.destination, weight=tup.weight)
        
    return Gn


def get_empirical_network_properties(Gd, shortest_path=False, largest_component=True):
    # network property ---------
    
    # empirical network model
    print("============empirical network model===================")
    ## number of nodes N
    n_node = Gd.number_of_nodes()
    ## number of link K
    n_edge = Gd.number_of_edges()
    ## ave. clustring coef <C>
    c = nx.average_clustering(Gd)
    ## ave. degree <K>
    k = np.mean(list(dict(Gd.degree()).values()))
    print("Number of nodes = ",n_node)
    print("Number of links = ",n_edge)
    print("Average clustering coefficient of the network = ",c)
    print("Average degree of the network = ",k)
    ## ave. shortest path <L>
    if shortest_path: 
        if largest_component:
            largest_component = sorted((Gd.subgraph(c) for c in nx.connected_components(Gd)), key = len, reverse=True)[0]
            l = nx.average_shortest_path_length(largest_component)
        else: 
            l = nx.average_shortest_path_length(Gd)
        print("Average shortest path = ",l)
    
    return n_node, n_edge, c, k, l 


def get_wattsstrogatz_network_properties(gs, n_edge, n_node, c, shortest_path=False, largest_component=True):
    # small-world model a.k.a. Watts-Strogatz model
    print("============small-world network model===================")
    k = int(n_edge/n_node)*2
    C0 = nx.average_clustering(nx.watts_strogatz_graph(n_node,k,0))
    ## probability of rewiring each edge
    p_s = 1-pow(c/C0,1/3)
    print("p = ",p_s)
    gs=nx.watts_strogatz_graph(n_node,k,p_s,seed=123)
    
    ## number of nodes N
    n_node_s=gs.number_of_nodes()
    ## number of link K
    n_edge_s=gs.number_of_edges()
    ## ave. clustring coef <C>
    c_s = nx.average_clustering(gs)
    ## ave. degree <K>
    k_s = np.mean(list(dict(gs.degree()).values()))
    ## ave. shortest path <L>
    print("Number of nodes = ",n_node_s)
    print("Number of links = ",n_edge_s)
    print("Average clustering coefficient of the network = ",c_s)
    print("Average degree of the network = ",k_s)
    l_s = np.NaN
    if shortest_path: 
        if largest_component:
            largest_component = sorted((gs.subgraph(c) for c in nx.connected_components(gs)), key = len, reverse=True)[0]
            l_s = nx.average_shortest_path_length(largest_component)
        else: 
            l_s = nx.average_shortest_path_length(gs)
        print("Average shortest path = ", l_s)

    return n_node_s, n_edge_s, c_s, k_s, l_s 


def get_barabasialbert_network_propeties(gs, m_b, n_node, shortest_path=False, largest_component=True):

    #Barabasi-Albert network model
    print("============Barabasi-Albert network model===================")
    ## Set m. I totally forgot how to decide m. possibly, set m as the # of edges is close to the actual network...
    print("m = ",m_b)
    gb = nx.barabasi_albert_graph(n_node, m_b,seed=123)
    ## number of nodes N
    n_node_b=gb.number_of_nodes()
    ## number of link K
    n_edge_b=gb.number_of_edges()
    ## ave. clustring coef <C>
    c_b = nx.average_clustering(gb)
    ## ave. degree <K>
    k_b = np.mean(list(dict(gb.degree()).values()))
    ## ave. shortest path <L>
    print("Number of nodes = ",n_node_b)
    print("Number of links = ",n_edge_b)
    print("Average clustering coefficient of the network = ",c_b)
    print("Average degree of the network = ",k_b)
    l_b = np.NaN
    if shortest_path: 
        if largest_component:
            largest_component = sorted((gs.subgraph(c) for c in nx.connected_components(gs)), key = len, reverse=True)[0]
            l_b = nx.average_shortest_path_length(largest_component)
        else: 
            l_b = nx.average_shortest_path_length(gs)
        print("Average shortest path = ", l_b)

    return n_node_b, n_edge_b, c_b, k_b, l_b 
            
    
def get_erdosrenyi_network_properties(gs, n_node, n_edge, shortest_path=False, largest_component=True):
    
    # random graph, a.k.a Erdős-Rényi graph
    print("============Erdős-Rényi network model===================")
    ## Probability for edge creation
    p_e = 2*n_edge/(n_node*(n_node-1))
    print("p = ",p_e)
    ge = nx.erdos_renyi_graph(n_node, p_e, seed=123, directed=True)
    #CC= sorted((ge.subgraph(c) for c in nx.connected_components(ge)), key = len, reverse=True)[0]
    ## number of nodes N
    n_node_e=ge.number_of_nodes()
    ## number of link K
    n_edge_e=ge.number_of_edges()
    ## ave. clustring coef <C>
    c_e = nx.average_clustering(ge)
    ## ave. degree <K>
    k_e = np.mean(list(dict(ge.degree()).values()))
    print("Number of nodes = ",n_node_e)
    print("Number of links = ",n_edge_e)
    print("Average clustering coefficient of the network = ",c_e)
    print("Average degree of the network = ",k_e)
    ## ave. shortest path <L> choose either of below functions
    l_e = np.NaN
    if shortest_path: 
        if largest_component:
            largest_component = sorted((gs.subgraph(c) for c in nx.connected_components(gs)), key = len, reverse=True)[0]
            l_e = nx.average_shortest_path_length(largest_component)
        else: 
            l_e = nx.average_shortest_path_length(gs)
        print("Average shortest path = ", l_e)

    return n_node_e, n_edge_e, c_e, k_e, l_e